{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spikee.utils import evaluate\n",
    "from spikee.utils.batcher import batch_provider\n",
    "from spikee.utils import conv\n",
    "from spikee.models.SpikE import SpikE_Scorer_AS as scorer\n",
    "from spikee.training import train_and_evaluate as train\n",
    "from spikee.utils import preprocessing\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "np.random.seed(12312345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = '../data/Industrial_Automation'\n",
    "train_data, valid_data, num_nodes, num_predicates = conv.load_data(datapath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating data for filtered metrics...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dodo/anaconda3/envs/test/lib/python3.8/site-packages/numpy/core/_asarray.py:171: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return array(a, dtype, copy=False, order=order, subok=True)\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists('{}/valid_filter_po.npy'.format(datapath)):\n",
    "    print('Creating data for filtered metrics...')\n",
    "    preprocessing.filter_data(datapath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'dim': 20,\n",
    "    'input_size': 40,\n",
    "    'tau': 0.5,\n",
    "    'batchsize': 50,\n",
    "    'delta': 0.01,\n",
    "    'lr': 1.0,\n",
    "    'L2': 0.,\n",
    "    'steps': 8001,\n",
    "    'neg_samples': 2,\n",
    "    'maxspan': 2,\n",
    "}\n",
    "\n",
    "eval_points = list(range(0, 8001, 1000))\n",
    "seed = np.random.randint(1e8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\n",
      "\n",
      "train ~~~~SP~~~~ hits@1: 0.0002 __hits@3: 0.0005 __ mean: 1833.0226 __ MRR: 0.0023\n",
      "\n",
      "train ~~~~PO~~~~ hits@1: 0.0004 __hits@3: 0.0008 __ mean: 1723.7564 __ MRR: 0.0033\n",
      "\n",
      "valid ~~~~SP~~~~ hits@1: 0.0004 __hits@3: 0.0012 __ mean: 1708.2603 __ MRR: 0.0030\n",
      "\n",
      "valid ~~~~PO~~~~ hits@1: 0.0004 __hits@3: 0.0008 __ mean: 1482.5617 __ MRR: 0.0036\n",
      "\n",
      "ETA 5418.97min \n",
      "\n",
      "\n",
      "1000:\n",
      "\n",
      "train ~~~~SP~~~~ hits@1: 0.4976 __hits@3: 0.6786 __ mean: 57.8085 __ MRR: 0.6044\n",
      "\n",
      "train ~~~~PO~~~~ hits@1: 0.3463 __hits@3: 0.3832 __ mean: 467.5513 __ MRR: 0.3753\n",
      "\n",
      "valid ~~~~SP~~~~ hits@1: 0.2899 __hits@3: 0.4827 __ mean: 178.5337 __ MRR: 0.4050\n",
      "\n",
      "valid ~~~~PO~~~~ hits@1: 0.1920 __hits@3: 0.2075 __ mean: 925.1596 __ MRR: 0.2071\n",
      "\n",
      "ETA 35.44min \n",
      "\n",
      "\n",
      "2000:\n",
      "\n",
      "train ~~~~SP~~~~ hits@1: 0.6781 __hits@3: 0.8389 __ mean: 21.1699 __ MRR: 0.7646\n",
      "\n",
      "train ~~~~PO~~~~ hits@1: 0.4108 __hits@3: 0.5044 __ mean: 278.4984 __ MRR: 0.4678\n",
      "\n",
      "valid ~~~~SP~~~~ hits@1: 0.4612 __hits@3: 0.6342 __ mean: 97.1543 __ MRR: 0.5646\n",
      "\n",
      "valid ~~~~PO~~~~ hits@1: 0.2688 __hits@3: 0.2797 __ mean: 745.4121 __ MRR: 0.2823\n",
      "\n",
      "ETA 28.14min \n",
      "\n",
      "\n",
      "3000:\n",
      "\n",
      "train ~~~~SP~~~~ hits@1: 0.7490 __hits@3: 0.9174 __ mean: 8.5649 __ MRR: 0.8387\n",
      "\n",
      "train ~~~~PO~~~~ hits@1: 0.5379 __hits@3: 0.5873 __ mean: 192.6110 __ MRR: 0.5730\n",
      "\n",
      "valid ~~~~SP~~~~ hits@1: 0.5855 __hits@3: 0.7568 __ mean: 46.6719 __ MRR: 0.6893\n",
      "\n",
      "valid ~~~~PO~~~~ hits@1: 0.3484 __hits@3: 0.3727 __ mean: 541.6175 __ MRR: 0.3707\n",
      "\n",
      "ETA 22.81min \n",
      "\n",
      "\n",
      "4000:\n",
      "\n",
      "train ~~~~SP~~~~ hits@1: 0.8278 __hits@3: 0.9499 __ mean: 5.0293 __ MRR: 0.8890\n",
      "\n",
      "train ~~~~PO~~~~ hits@1: 0.5409 __hits@3: 0.6142 __ mean: 159.4073 __ MRR: 0.5865\n",
      "\n",
      "valid ~~~~SP~~~~ hits@1: 0.6500 __hits@3: 0.8063 __ mean: 25.2351 __ MRR: 0.7385\n",
      "\n",
      "valid ~~~~PO~~~~ hits@1: 0.3983 __hits@3: 0.4137 __ mean: 460.3630 __ MRR: 0.4182\n",
      "\n",
      "ETA 18.00min \n",
      "\n",
      "\n",
      "5000:\n",
      "\n",
      "train ~~~~SP~~~~ hits@1: 0.8288 __hits@3: 0.9528 __ mean: 4.7336 __ MRR: 0.8929\n",
      "\n",
      "train ~~~~PO~~~~ hits@1: 0.6065 __hits@3: 0.6443 __ mean: 129.1486 __ MRR: 0.6356\n",
      "\n",
      "valid ~~~~SP~~~~ hits@1: 0.6581 __hits@3: 0.7950 __ mean: 16.8380 __ MRR: 0.7421\n",
      "\n",
      "valid ~~~~PO~~~~ hits@1: 0.4340 __hits@3: 0.4543 __ mean: 414.8605 __ MRR: 0.4524\n",
      "\n",
      "ETA 13.38min \n",
      "\n",
      "\n",
      "6000:\n",
      "\n",
      "train ~~~~SP~~~~ hits@1: 0.8841 __hits@3: 0.9720 __ mean: 3.3778 __ MRR: 0.9285\n",
      "\n",
      "train ~~~~PO~~~~ hits@1: 0.6026 __hits@3: 0.6730 __ mean: 93.5370 __ MRR: 0.6485\n",
      "\n",
      "valid ~~~~SP~~~~ hits@1: 0.7024 __hits@3: 0.8250 __ mean: 12.2724 __ MRR: 0.7778\n",
      "\n",
      "valid ~~~~PO~~~~ hits@1: 0.4312 __hits@3: 0.4685 __ mean: 380.8084 __ MRR: 0.4580\n",
      "\n",
      "ETA 8.89min \n",
      "\n",
      "\n",
      "7000:\n",
      "\n",
      "train ~~~~SP~~~~ hits@1: 0.8912 __hits@3: 0.9757 __ mean: 3.3569 __ MRR: 0.9333\n",
      "\n",
      "train ~~~~PO~~~~ hits@1: 0.6266 __hits@3: 0.7139 __ mean: 70.4642 __ MRR: 0.6820\n",
      "\n",
      "valid ~~~~SP~~~~ hits@1: 0.7097 __hits@3: 0.8368 __ mean: 11.9582 __ MRR: 0.7849\n",
      "\n",
      "valid ~~~~PO~~~~ hits@1: 0.4527 __hits@3: 0.4876 __ mean: 362.2257 __ MRR: 0.4803\n",
      "\n",
      "ETA 4.44min \n",
      "\n",
      "\n",
      "8000:\n",
      "\n",
      "train ~~~~SP~~~~ hits@1: 0.9141 __hits@3: 0.9706 __ mean: 3.4455 __ MRR: 0.9427\n",
      "\n",
      "train ~~~~PO~~~~ hits@1: 0.6287 __hits@3: 0.6964 __ mean: 56.0682 __ MRR: 0.6769\n",
      "\n",
      "valid ~~~~SP~~~~ hits@1: 0.6833 __hits@3: 0.8002 __ mean: 10.1953 __ MRR: 0.7587\n",
      "\n",
      "valid ~~~~PO~~~~ hits@1: 0.4645 __hits@3: 0.4864 __ mean: 350.3979 __ MRR: 0.4826\n",
      "\n",
      "ETA 0.00min \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "batcher = batch_provider(train_data, params['batchsize'], params['neg_samples'], seed)\n",
    "model = scorer(num_nodes, num_predicates, params['dim'], params['input_size'], params['tau'], params['maxspan'], seed)\n",
    "optimizer = torch.optim.Adagrad([model.entities.weights.weight, model.predicates.weight], lr=params['lr'], weight_decay = params['L2'])\n",
    "train(optimizer, batcher, model,params['delta'], params['steps'], eval_points, datapath = datapath, data = [train_data, valid_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
